{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from LAC import LAC\n",
    "lac = LAC(mode='seg')\n",
    "import re\n",
    "import shutil\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading file paths\n",
    "fp_train = 'Fudan/train'\n",
    "fp_test ='Fudan/answer'\n",
    "fp_target_63 ='targetdata/year1963'\n",
    "fp_target_90 ='targetdata/year1990'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step One: construct functions needed for data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define needed functions\n",
    "\n",
    "# This function will delete the characters of '【' , '】', and '\\n' in the Chinese text\n",
    "# the input is a list of lists\n",
    "def clean_text(file_readlines):\n",
    "    _special_symbles = {ord('【'): None, ord('】'): None, ord('\\n'): None, ord('＊'):None}\n",
    "    _temp = [i.translate(_special_symbles) for i in file_readlines]\n",
    "    return [i.strip() for i in _temp]\n",
    "\n",
    "\n",
    "# this function will segment one single Chinese document and same it as one string in a list\n",
    "def seg_chinese(fp):\n",
    "\n",
    "    try:\n",
    "        with open(fp, 'r') as fh:\n",
    "            _text = fh.readlines()\n",
    "\n",
    "            _text = lac.run(clean_text(_text))\n",
    "            result = ' '.join([e for i in _text for e in i])\n",
    "    except IOError:\n",
    "        result = fp\n",
    "\n",
    "    return result\n",
    "\n",
    "#  this funciton will produce a dictionary with file path as keys, tag as values\n",
    "def dir_tag_pair(directory):\n",
    "\n",
    "    files = os.listdir(directory)\n",
    "    return {os.path.join(directory,i):re.split('-',i)[1]\n",
    "            for i in files if i.startswith('C')}\n",
    "\n",
    "\n",
    "# the function will take the output of function dir_tag_pair as input, and produce two\n",
    "# lists. One is a list of strings, each is one segmented Chinese document. Anther is a\n",
    "# list of corresponding tags.\n",
    "def process_sub_directory(directory, tag):\n",
    "\n",
    "    files= os.listdir(directory)\n",
    "\n",
    "    texts = []\n",
    "    tags = []\n",
    "\n",
    "    for file in files:\n",
    "        if file.endswith('txt'):\n",
    "            texts.append(seg_chinese(os.path.join(directory,file)))\n",
    "            tags.append(tag)\n",
    "\n",
    "    return texts, tags\n",
    "\n",
    "# This function will output two lists, one consists of a list of documents, another of all tags.\n",
    "# the input is the file path. The output are intended for the inputs of CounterVecterizer\n",
    "def process_directory(directory):\n",
    "\n",
    "    alltextdata = []\n",
    "    alltag=[]\n",
    "\n",
    "    _tempd =dir_tag_pair(directory)\n",
    "    for k in _tempd.keys():\n",
    "        _text, _tag = process_sub_directory(k,_tempd[k])\n",
    "        alltextdata.extend(_text)\n",
    "        alltag.extend(_tag)\n",
    "\n",
    "    return alltextdata, alltag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step Two Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  preprocessing the train data\n",
    "alltextdata, y_train =process_directory(fp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn train data into vectors and use them to train the model\n",
    "vectorizer = CountVectorizer()\n",
    "model = MultinomialNB()\n",
    "x_train = vectorizer.fit_transform(alltextdata)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step Three 1) test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the test data\n",
    "test_alltextdata, y_test = process_directory(fp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the test data into vectors and use them to test the model\n",
    "x_text = vectorizer.transform(test_alltextdata)\n",
    "y_hat = model.predict(x_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step Three 2) report metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy:', metrics.accuracy_score(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step Four Manually Accessing the External Validity of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions needed to process the target data(People's Daily Newspaper text in 1963 and 1990)\n",
    "def processing_target_data(fp):\n",
    "    _result = []\n",
    "    for i in os.listdir(fp):\n",
    "        if i.endswith('md'):\n",
    "            with open(os.path.join(fp,i)) as fh:\n",
    "                raw_a = fh.readlines()\n",
    "\n",
    "                article = [sent.strip() for sent in raw_a[6:]]\n",
    "                article = [e.replace('\\u3000', '，') for e in article]\n",
    "                pair = (raw_a[0], article)\n",
    "                _result.append(pair)\n",
    "    return _result\n",
    "\n",
    "def segment_target_data(the_tuple):\n",
    "    _result =[]\n",
    "    for i in the_tuple:\n",
    "        _text= lac.run(i[1])\n",
    "        segmented_text=' '.join([item for l in _text for item in l])\n",
    "\n",
    "        pair = (i[0], [segmented_text])\n",
    "        _result.append(pair)\n",
    "\n",
    "    return pd.DataFrame.from_records(_result, columns=['title','text'])\n",
    "\n",
    "\n",
    "def predict_label(x):\n",
    "    x_train = vectorizer.transform(x)\n",
    "    return model.predict(x_train)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing the target data and apply the model on the data to predict labels\n",
    "# two dataframes will be produced, corresponding to 1963 dataset and 1990 dataset respectively.\n",
    "# The dataframe has three columns, corresponding to the title, document text, and predicted label.\n",
    "target_63 = processing_target_data(fp_target_63)\n",
    "df = segment_target_data(target_63)\n",
    "df63['predicted_label'] = df63['text'].apply(lambda x: predict_label(x))\n",
    "target_90 = processing_target_data(fp_target_90)\n",
    "df90 = segment_target_data(target_90)\n",
    "df90['predicted_label'] = df90['text'].apply(lambda x: predict_label(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random selecting 30 samples from each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df63_sample = df63.iloc[np.random.choice(len(df63), 30)]\n",
    "df90_sample = df90.iloc[np.random.choice(len(df90), 30)]\n",
    "# I forgot to set the seed... np.random.seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save the samples into two csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df63_sample.to_csv('df63_sample.csv')\n",
    "df90_sample.to_csv('df90_sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually inspect the samples and assign a human determined label to each sample, and save them into two dataframes. The two new dataframes have same four column names: title, text, predicted label, true label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels_63 = pd.read_csv('df63_sample_tcsv.csv', index_col =0)['predicted_label'].tolist()\n",
    "true_labels_63 =pd.read_csv('df63_sample_tcsv.csv', index_col =0)['true_label'].tolist()\n",
    "predicted_labels_90 = pd.read_csv('df90_sample_tcsv.csv', index_col =0)['predicted_label'].tolist()\n",
    "true_labels_90 =pd.read_csv('df90_sample_tcsv.csv', index_col =0)['True_label'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compare the model predicted labels and human determined ones, and print out the accuracy metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.accuracy_score(true_labels_63, predicted_labels_63))\n",
    "print(metrics.classification_report(true_labels_63, predicted_labels_63))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.accuracy_score(true_labels_90, predicted_labels_90))\n",
    "print(metrics.classification_report(true_labels_90, predicted_labels_90))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}